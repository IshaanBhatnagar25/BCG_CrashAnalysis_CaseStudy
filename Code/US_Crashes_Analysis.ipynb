{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "#Creating the Spark Session:\n",
    "spark = SparkSession.builder.appName(\"CrashesAnalysis\").getOrCreate()\n",
    "\n",
    "#Reading Config File:\n",
    "charges_file_path = spark.conf.get(\"spark.charges_file_path\")\n",
    "damages_file_path = spark.conf.get(\"spark.damages_file_path\")\n",
    "endorse_file_path = spark.conf.get(\"spark.endorse_file_path\")\n",
    "primary_person_file_path = spark.conf.get(\"spark.primary_person_file_path\")\n",
    "restrict_file_path = spark.conf.get(\"spark.restrict_file_path\")\n",
    "units_file_path = spark.conf.get(\"spark.units_file_path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the CSVs in DataFrames\n",
    "df_charges = spark.read.csv(charges_file_path,header=True)\n",
    "df_damages = spark.read.csv(damages_file_path,header=True)\n",
    "df_endorse = spark.read.csv(endorse_file_path,header=True)\n",
    "df_primary_person = spark.read.csv(primary_person_file_path,header=True)\n",
    "df_restrict = spark.read.csv(restrict_file_path,header=True)\n",
    "df_units = spark.read.csv(df_units,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analytics 1: Find the number of crashes (accidents) \n",
    "#in which number of persons killed are male?\n",
    "\n",
    "print(\"Analysis 1: Find the number of crashes (accidents) in which number of persons killed are male?\")\n",
    "print(\"Analysis 1 Solution:\")\n",
    "\n",
    "#Analysis:\n",
    "#No of Acc = 182, Distinct Acc = 180 (In 2 Acc, 2-2 Males died in crash_id '15429998','15379024')\n",
    "df_primary_person.where(\"PRSN_INJRY_SEV_ID = 'KILLED' and PRSN_GNDR_ID = 'MALE'\").select(F.col(\"CRASH_ID\")).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "757"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analysis 2: How many two wheelers are booked for crashes:\n",
    "\n",
    "print(\"Analysis 2: How many two wheelers are booked for crashes\")\n",
    "print(\"Analysis 2 Solution:\")\n",
    "df_units.where(\"VEH_BODY_STYL_ID in ('MOTORCYCLE','POLICE MOTORCYCLE')\").select(F.col(\"CRASH_ID\")).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|DRVR_LIC_STATE_ID|count|\n",
      "+-----------------+-----+\n",
      "|Texas            |53319|\n",
      "+-----------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Analysis 3: Which state has highest number of accidents \n",
    "#in which females are involved? \n",
    "\n",
    "print(\"Analysis 3: Which state has highest number of accidents in which females are involved?\")\n",
    "print(\"Analysis 3 Solution:\")\n",
    "\n",
    "df_primary_person.where(\"PRSN_GNDR_ID = 'FEMALE'\").groupby(F.col(\"DRVR_LIC_STATE_ID\")).count().distinct().sort(F.col('count').desc()).show(1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|VEH_MAKE_ID |\n",
      "+------------+\n",
      "|NISSAN      |\n",
      "|HONDA       |\n",
      "|NA          |\n",
      "|GMC         |\n",
      "|JEEP        |\n",
      "|HYUNDAI     |\n",
      "|KIA         |\n",
      "|CHRYSLER    |\n",
      "|FREIGHTLINER|\n",
      "|MAZDA       |\n",
      "+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Analysis 4: Which are the Top 5th to 15th VEH_MAKE_IDs that \n",
    "#contribute to a largest number of injuries including death\n",
    "\n",
    "print(\"Analysis 4: Which are the Top 5th to 15th VEH_MAKE_IDs that contribute to a largest number of injuries including death\")\n",
    "print(\"Analysis 4 Solution:\")\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "df_req_units = df_units.select(F.col(\"VEH_MAKE_ID\"),F.col(\"CRASH_ID\"))\n",
    "#df_req_units.show(5,False)\n",
    "df_injured_person = df_primary_person.where(\"PRSN_INJRY_SEV_ID in ('KILLED','NON-INCAPACITATING INJURY','INCAPACITATING INJURY','POSSIBLE INJURY')\").select(F.col('CRASH_ID')).distinct()\n",
    "#df_injured_person.show(5,False)\n",
    "join_cond = [df_injured_person['crash_id'] == df_req_units['crash_id']]\n",
    "df_units_with_injury = df_req_units.join(df_injured_person, on = join_cond, how='inner').drop(df_req_units['crash_id'])\n",
    "df_req = df_units_with_injury.groupby(F.col(\"VEH_MAKE_ID\")).count().sort(F.col('count').desc())\n",
    "df_req_rnk = df_req.withColumn(\"crash_cnt\",F.row_number().over(Window.orderBy(F.col('count').desc())))\n",
    "df_req_rnk.where(\"crash_cnt between 5 and 15\").select(F.col('VEH_MAKE_ID')).show(10,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+-----------------+\n",
      "|VEH_BODY_STYL_ID                 |PRSN_ETHNICITY_ID|\n",
      "+---------------------------------+-----------------+\n",
      "|BUS                              |HISPANIC         |\n",
      "|NA                               |WHITE            |\n",
      "|VAN                              |WHITE            |\n",
      "|PICKUP                           |WHITE            |\n",
      "|SPORT UTILITY VEHICLE            |WHITE            |\n",
      "|PASSENGER CAR, 4-DOOR            |WHITE            |\n",
      "|FIRE TRUCK                       |WHITE            |\n",
      "|TRUCK                            |WHITE            |\n",
      "|UNKNOWN                          |UNKNOWN          |\n",
      "|AMBULANCE                        |WHITE            |\n",
      "|POLICE CAR/TRUCK                 |WHITE            |\n",
      "|MOTORCYCLE                       |WHITE            |\n",
      "|YELLOW SCHOOL BUS                |WHITE            |\n",
      "|POLICE MOTORCYCLE                |HISPANIC         |\n",
      "|PASSENGER CAR, 2-DOOR            |WHITE            |\n",
      "|TRUCK TRACTOR                    |WHITE            |\n",
      "|FARM EQUIPMENT                   |WHITE            |\n",
      "|NEV-NEIGHBORHOOD ELECTRIC VEHICLE|WHITE            |\n",
      "|OTHER  (EXPLAIN IN NARRATIVE)    |WHITE            |\n",
      "|NOT REPORTED                     |HISPANIC         |\n",
      "+---------------------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Analysis 5: For all the body styles involved in crashes, \n",
    "#mention the top ethnic user group of each unique body styleÂ  \n",
    "\n",
    "print(\"Analysis 5: For all the body styles involved in crashes, mention the top ethnic user group of each unique body style\")\n",
    "print(\"Analysis 5 Solution:\")\n",
    "\n",
    "windowDept = Window.partitionBy(F.col('VEH_BODY_STYL_ID')).orderBy(F.col(\"count\").desc())\n",
    "\n",
    "df_person_with_ethnicity = df_primary_person.select(F.col('CRASH_ID'),F.col('PRSN_ETHNICITY_ID')).distinct()\n",
    "df_req_units = df_units.select(F.col(\"VEH_BODY_STYL_ID\"),F.col(\"CRASH_ID\"))\n",
    "join_cond = [df_person_with_ethnicity['crash_id'] == df_req_units['crash_id']]\n",
    "df_units_with_ethnicity = df_req_units.join(df_person_with_ethnicity, on = join_cond, how='inner').drop(df_req_units['crash_id'])\n",
    "df_rnked = df_units_with_ethnicity.groupby(F.col('VEH_BODY_STYL_ID'),F.col('PRSN_ETHNICITY_ID')).count().sort(F.col('VEH_BODY_STYL_ID'),F.col('count').desc())\n",
    "df_req = df_rnked.withColumn(\"body_type_rnk\",F.row_number().over(windowDept))\n",
    "#df_req.show(100,False)\n",
    "df_res = df_req.where(\"body_type_rnk = 1\").select(F.col('VEH_BODY_STYL_ID'),F.col('PRSN_ETHNICITY_ID'))\n",
    "df_res.show(50,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|DRVR_ZIP|count|\n",
      "+--------+-----+\n",
      "|null    |347  |\n",
      "|78521   |75   |\n",
      "|75067   |57   |\n",
      "|78753   |55   |\n",
      "|75070   |52   |\n",
      "+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Analysis 6: Among the crashed cars, what are the Top 5 Zip Codes with highest number crashes \n",
    "#with alcohols as the contributing factor to a crash (Use Driver Zip Code)\n",
    "\n",
    "print(\"Analysis 6: Among the crashed cars, what are the Top 5 Zip Codes with highest number crashes with alcohols as the contributing factor to a crash (Use Driver Zip Code)\")\n",
    "print(\"Analysis 6 Solution:\")\n",
    "\n",
    "df_alc_crashes = df_units.where(\"VEH_BODY_STYL_ID in ('PASSENGER CAR, 2-DOOR','POLICE CAR/TRUCK','PASSENGER CAR, 4-DOOR','SPORT UTILITY VEHICLE')\").where(\"CONTRIB_FACTR_1_ID in ('UNDER INFLUENCE - ALCOHOL','HAD BEEN DRINKING') or CONTRIB_FACTR_2_ID in ('UNDER INFLUENCE - ALCOHOL','HAD BEEN DRINKING') or CONTRIB_FACTR_P1_ID in ('UNDER INFLUENCE - ALCOHOL','HAD BEEN DRINKING')\").select(F.col(\"crash_id\"),F.col('VEH_BODY_STYL_ID'))\n",
    "#df_alc_crashes.show(10,False)\n",
    "df_person_with_zip = df_primary_person.select(F.col(\"crash_id\"),F.col('DRVR_ZIP'))\n",
    "join_cond = [df_alc_crashes['crash_id'] == df_person_with_zip['crash_id']]\n",
    "df_req = df_alc_crashes.join(df_person_with_zip, on = join_cond, how='inner').drop(df_person_with_zip['crash_id'])\n",
    "#df_req.show(15,False)\n",
    "df_res = df_req.groupby(F.col('DRVR_ZIP')).count()\n",
    "df_res.sort(F.col('count').desc()).show(5,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8849"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analysis 7: Count of Distinct Crash IDs where No Damaged Property was observed \n",
    "#and Damage Level (VEH_DMAG_SCL~) is above 4 \n",
    "#and car avails Insurance\n",
    "\n",
    "print(\"Analysis 7: Count of Distinct Crash IDs where No Damaged Property was observed and Damage Level (VEH_DMAG_SCL~) is above 4 and car avails Insurance\")\n",
    "print(\"Analysis 7 Solution:\")\n",
    "\n",
    "df_damage_cid = df_damages.select(F.col('crash_id')).distinct()\n",
    "df_unit_dmg_lvl = df_units.where(\"VEH_DMAG_SCL_1_ID in('DAMAGED 5','DAMAGED 6','DAMAGED 7 HIGHEST') or VEH_DMAG_SCL_2_ID in('DAMAGED 5','DAMAGED 6','DAMAGED 7 HIGHEST')\")\n",
    "df_unit_with_insurance = df_unit_dmg_lvl.where(\"FIN_RESP_TYPE_ID like '%INSURANCE%'\").select(F.col('crash_id'),F.col('VEH_DMAG_SCL_1_ID'),F.col('VEH_DMAG_SCL_2_ID'),F.col('FIN_RESP_TYPE_ID'))\n",
    "join_cond = [df_unit_with_insurance['crash_id'] == df_damage_cid['crash_id']]\n",
    "df_req = df_unit_with_insurance.join(df_damage_cid, on = join_cond, how='left_anti').distinct()#.drop(df_person_with_zip['crash_id'])\n",
    "df_req.select(F.col('crash_id')).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|VEH_MAKE_ID|\n",
      "+-----------+\n",
      "|FORD       |\n",
      "|CHEVROLET  |\n",
      "|TOYOTA     |\n",
      "|DODGE      |\n",
      "|NISSAN     |\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Analysis 8: Determine the Top 5 Vehicle Makes where drivers are charged with speeding related offences, \n",
    "#has licensed Drivers, \n",
    "#uses top 10 used vehicle colours \n",
    "#and has car licensed with the Top 25 states with highest number of offences (to be deduced from the data)\n",
    "\n",
    "print(\"Analysis 8: Determine the Top 5 Vehicle Makes where drivers are charged with speeding related offences, has licensed Drivers, uses top 10 used vehicle colours and has car licensed with the Top 25 states with highest number of offences (to be deduced from the data)\")\n",
    "print(\"Analysis 8 Solution:\")\n",
    "\n",
    "#Getting crashes where charge was speeding related:\n",
    "df_speeding_charge = df_charges.where(\"charge like '%SPEED%'\").select(F.col('crash_id'),F.col('CHARGE'))\n",
    "\n",
    "#Getting the top 25 states with highest number of offences:\n",
    "df_top_state = df_primary_person.groupby(F.col('DRVR_LIC_STATE_ID')).count()\n",
    "df_rnk_state = df_top_state.withColumn('state_rnk',F.row_number().over(Window.orderBy(F.col('count').desc())))\n",
    "df_rnk_state_req = df_rnk_state.where(\"state_rnk <= 25\").select(F.col('DRVR_LIC_STATE_ID'))\n",
    "#df_rnk_state_req.show(10,False)\n",
    "\n",
    "#Getting Licensed Drivers:\n",
    "df_lic_drvr = df_primary_person.where(\"DRVR_LIC_TYPE_ID in ('COMMERCIAL DRIVER LIC.','DRIVER LICENSE')\").select(F.col('crash_id'),F.col('DRVR_LIC_STATE_ID'),F.col('DRVR_LIC_TYPE_ID'))\n",
    "\n",
    "#Getting Licensed Drivers those have car licensed with the Top 25 states with highest number of offences:\n",
    "df_lic_drvr_top_state = df_lic_drvr.join(df_rnk_state_req, on = [df_lic_drvr['DRVR_LIC_STATE_ID'] == df_rnk_state_req['DRVR_LIC_STATE_ID']],how = 'inner').drop(df_rnk_state_req['DRVR_LIC_STATE_ID'])\n",
    "#df_lic_drvr_top_state.show(10,False)\n",
    "\n",
    "#Getting Licensed Drivers from Top states with speeding related charges:\n",
    "drvr_speed_cond = [df_lic_drvr_top_state['crash_id'] == df_speeding_charge['crash_id']]\n",
    "df_lic_drvr_speeding = df_lic_drvr_top_state.join(df_speeding_charge, on = drvr_speed_cond, how = 'inner').drop(df_speeding_charge['crash_id'])\n",
    "#df_lic_drvr_speeding.show(15,False)\n",
    "\n",
    "#Getting the top 10 used vehicles colours:\n",
    "df_top_clr_vhcl = df_units.groupby(F.col('VEH_COLOR_ID')).count()\n",
    "df_rnk_clr = df_top_clr_vhcl.withColumn('clr_rnk',F.row_number().over(Window.orderBy(F.col('count').desc())))\n",
    "df_rnk_clr_req = df_rnk_clr.where(\"clr_rnk <= 10\").select(F.col('VEH_COLOR_ID'))\n",
    "#df_rnk_clr_req.show(10,False)\n",
    "\n",
    "#Getting crash_ids where the colour of car was in top 10 used vehicles colours:\n",
    "df_units_req = df_units.join(df_rnk_clr_req, on = [df_units['VEH_COLOR_ID'] == df_rnk_clr_req['VEH_COLOR_ID']], how = 'inner').drop(df_rnk_clr_req['VEH_COLOR_ID'])\n",
    "df_units_top_clr = df_units_req.select(F.col('crash_id'),F.col('VEH_COLOR_ID'),F.col('VEH_MAKE_ID'))\n",
    "#df_units_top_clr.show(10,False)\n",
    "\n",
    "#Getting licensed speedy drivers from Top states driving top coloured cars:\n",
    "drvr_clr_cond = [df_lic_drvr_speeding['crash_id'] == df_units_top_clr['crash_id']]\n",
    "df_req = df_lic_drvr_speeding.join(df_units_top_clr, on = drvr_clr_cond,how = 'inner')\n",
    "\n",
    "#Getting the Top Vehicle Makers:\n",
    "df_veh_req = df_req.groupby(F.col('VEH_MAKE_ID')).count()\n",
    "df_veh_req_rnk = df_veh_req.withColumn('veh_rnk',F.row_number().over(Window.orderBy(F.col('count').desc())))\n",
    "df_veh_req_rnk.where(\"veh_rnk <= 5\").select(F.col('VEH_MAKE_ID')).show(10,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
